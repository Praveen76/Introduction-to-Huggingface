{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praveen76/Introduction-to-Huggingface/blob/main/Fine_Tunning_BERT_Model_on_GLUE_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Huggingface: Fine Tunning BERT using Built in Data**"
      ],
      "metadata": {
        "id": "iCwQ6LZx2C8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objectives:\n",
        "\n",
        "At the end of the experiment you will be able to understand  :\n",
        "\n",
        "* How datasets are represented in HF\n",
        "* Trainer and trainingArguments objects\n",
        "* Computing Metrics\n",
        "* Saving and loading the trained model"
      ],
      "metadata": {
        "id": "KM-pOa7S1OLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "r3iM7nYp_J5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f078b360-5a04-4a1a-c69f-1bf622d5095e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.0/410.6 MB\u001b[0m \u001b[31m163.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accelerate is a library that enables the same PyTorch code to be run across any distributed configuration by adding just four lines of code, making training and inference at scale made simple, efficient and adaptable."
      ],
      "metadata": {
        "id": "w-KGCQIF_rJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "BjmSAoN29QTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face Datasets Library\n"
      ],
      "metadata": {
        "id": "DmLOuovi1jSk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOpFIwY9lzZ7"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading the dataset**\n",
        "Built in data sets are included with the data sets package. Using a single line of code, we can load in the data set  which  are well formatted  and processed for us to use."
      ],
      "metadata": {
        "id": "gnEmSp3x2RT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "#rd1=load_dataset(\"amazon_polarity\") # dataset for sentiment analysis\n",
        "rd2=load_dataset(\"glue\",\"sst2\")     # Part of GLUE Benchmark"
      ],
      "metadata": {
        "id": "LZsbllFu1wEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling the load data set function, returns a data set dict object, which is like a dictionary that may contain multiple data sets like -  a train dataset, validation dataset and test dataset."
      ],
      "metadata": {
        "id": "3Dta_Z-88-Cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rd2"
      ],
      "metadata": {
        "id": "rjGwwmis2YVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting different data and individual entries"
      ],
      "metadata": {
        "id": "IjHlKLBw-GaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rd2['train']"
      ],
      "metadata": {
        "id": "ulnMdowg2Yb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rd2['train'], '\\n')\n",
        "type(rd2['train'])"
      ],
      "metadata": {
        "id": "wSQ8sSVh2Ykm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rd2['train'].data"
      ],
      "metadata": {
        "id": "a8wVofQM8F-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rd2['train'][0]"
      ],
      "metadata": {
        "id": "BGtKkDOu2LN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rd2['train'][10:13]"
      ],
      "metadata": {
        "id": "RoAcjN388lU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rd2['train'].features"
      ],
      "metadata": {
        "id": "Yas_HvF_2AX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenization with DataSets**\n",
        "Recall that previously, we mentioned the need for truncation, padding and converting the tokenized data into PyTorch Tensors. Here, all of these steps will be handled  behind the scenes and no need to do anything. We are going to do is to partially apply the tokenizer to the data set dict object.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ik25FJ1g9HIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "DL1qiWY89BEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "nNwNJ2a39LCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentence = tokenizer(rd2['train'][0:3]['sentence'])\n",
        "from pprint import pprint\n",
        "pprint(tokenized_sentence)"
      ],
      "metadata": {
        "id": "3h1joIIq9kwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By calling the map method and passing in a tokenized function, the data set library automatically knows it should apply the same function to every data set i.e.train, validation and test.\n",
        "\n",
        " Note that in this example we apply only truncation but not padding or conversion into Pytorch Tensors. This will be handled behind the scenes by the trainer object we create later."
      ],
      "metadata": {
        "id": "REvSFVnOCvZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_fn(batch):\n",
        "  return tokenizer(batch['sentence'],truncation=True)"
      ],
      "metadata": {
        "id": "85D3Ls-3-EnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets=rd2.map(tokenize_fn,batched=True)"
      ],
      "metadata": {
        "id": "viH6eIVt-Pgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading Pre-Trained Model**"
      ],
      "metadata": {
        "id": "TPXfBiYpElKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model =AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=2)"
      ],
      "metadata": {
        "id": "tHeD1YZu-iA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(model)"
      ],
      "metadata": {
        "id": "qecYc5gc-iDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "5zCs4qGmALUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "eCX07y3jAMgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(model)"
      ],
      "metadata": {
        "id": "_48MxpMs9LFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Adding custom classifier layter and Freezing/Un-Freezing different layers**"
      ],
      "metadata": {
        "id": "OEaFCpYAFLzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(name)"
      ],
      "metadata": {
        "id": "XrMTbGJaf0fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing\n",
        "for name, param in model.named_parameters():\n",
        "     if name.startswith(\"distilbert\"): # choose whatever you like here\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "id": "Vl9qw4l2IPIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying of layers gradient\n",
        "for name, param in model.named_parameters():\n",
        "     print(name, param.requires_grad)"
      ],
      "metadata": {
        "id": "-rpzN_c6HRTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modifying last classifier layers**"
      ],
      "metadata": {
        "id": "lF5rsURm5AQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "LORB42Uf4wkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.pre_classifier"
      ],
      "metadata": {
        "id": "eDorephi7hes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.pre_classifier)\n",
        "model.pre_classifier = torch.nn.Linear(768,500)\n",
        "print(model.pre_classifier)"
      ],
      "metadata": {
        "id": "4F6lG1z79LHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.classifier)\n",
        "model.classifier = torch.nn.Linear(500,3)\n",
        "print(model.classifier)"
      ],
      "metadata": {
        "id": "KhfOZTPTBxTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "NbgkLalM9NIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Adding extra layer on top**"
      ],
      "metadata": {
        "id": "CJhJo1938YWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy"
      ],
      "metadata": {
        "id": "3uKXEnSi9hjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_model = copy.deepcopy(model)"
      ],
      "metadata": {
        "id": "uGoORHUh8hEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_model.classifier = torch.nn.Sequential(\n",
        "    (torch. nn.Linear(768, 192)),\n",
        "    torch.nn.Dropout(0.1),\n",
        "    (torch.nn.Linear(192, 2)))"
      ],
      "metadata": {
        "id": "KtADX5zV8Xen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_model"
      ],
      "metadata": {
        "id": "IHpHqbFh5xTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_before=[]\n",
        "for  name,p in model.named_parameters():\n",
        "  params_before.append(p.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "Hpp24FTuCnNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_before"
      ],
      "metadata": {
        "id": "CikrjMifDBbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Metrics**\n",
        "\n",
        "In HuggingFace, there are predefined metrics for the built in data sets and we are going to use that but we can define custom metrics as well.\n",
        "\n",
        "Specifically, there is a function called the load metric, also part of the data sets library. The arguments to this happens to be the same as the arguments into load data set for this example.\n",
        "\n",
        "More generally, however, you can pass in an argument to specify a specific metric like the Blue score or a python file where you've defined your own computations."
      ],
      "metadata": {
        "id": "wJficH7a97nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "metric =load_metric(\"glue\",\"sst2\")"
      ],
      "metadata": {
        "id": "icGBrZSrDIVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But,  we cannot pass this metric into the trainer directly. we need to define another function to do some extra work.\n",
        "\n",
        "Firstly, the metric we get back from `load_metric` is an object which has a method called `compute`, which will return a dictionary containing the computed metrics for a given task. This compute method it takes in to erase the predictions and the targets called a references.\n",
        "\n",
        "This will give us back a dictionary with the value of the metric or metrics with their names as keys."
      ],
      "metadata": {
        "id": "WfE5aqKNHNUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric.compute(predictions=[1,0,1], references=[1,0,0])"
      ],
      "metadata": {
        "id": "9J5Vi6w7DVIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(logits_and_labels):\n",
        "  logits, labels = logits_and_labels\n",
        "  predictions =np.argmax(logits,axis=-1)\n",
        "  return metric.compute(predictions=predictions,references=labels)"
      ],
      "metadata": {
        "id": "Eu5nmiAZDuU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training argument class**\n",
        "\n",
        "\n",
        "The training arguments class is like a training configuration. It allows to specify things like  - `where to save the outputs of the training process, how often to compute metrics, how many epochs to train for the learning rate, and many more`. There are tons of arguments into the constructor for this class. So check out the documentation.\n",
        "\n",
        "Note that the HuggingFace trainer uses an optimizer called **`Adam W`** by default, which is a slight variation of Adam.This is essentially built in and it's good enough for our purposes.If you want to use a different optimizer, you can always write your own custom training loop in plain Pytorch syntax as well."
      ],
      "metadata": {
        "id": "rnfX6i--9OWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments"
      ],
      "metadata": {
        "id": "hyj52cyV-hVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    'sample_trainer', #  directory where the trained model will be saved,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    num_train_epochs=1\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "D1J_saYU-h-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Trainer**\n",
        "\n",
        "Trainer object is what we use to run the training process. The arguments to the constructor are quite simple. We pass in the model, the trainer arguments, the training data set, the validation data set, the tokenizer and the metrics.\n",
        "\n",
        "Now, just call `trainer` and apply `train` method to train.\n",
        "\n"
      ],
      "metadata": {
        "id": "B3EniE6y9vFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer"
      ],
      "metadata": {
        "id": "UXz8DGFXEzw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset = tokenized_datasets[\"validation\"],\n",
        "    tokenizer =tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "yozHJeifEGfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        " # ~ 2 mint for tunning just last classifier layers\n",
        " # ~ 8 mint for tunning whole architecture"
      ],
      "metadata": {
        "id": "fNpRurWpE_26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Saving the model**"
      ],
      "metadata": {
        "id": "ZcgsEYJlKbR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('saved_model')"
      ],
      "metadata": {
        "id": "r0-EFIfIGAwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "h3SgH3qXGA1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Loading the saved model**"
      ],
      "metadata": {
        "id": "6GxwVdGLKgPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "zh3Dvzz-GBEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = pipeline('text-classification',model='saved_model',device=0)# ignore_mismatched_sizes=True)"
      ],
      "metadata": {
        "id": "SKjG3Gm0Gb1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model('this is not a good book to read')"
      ],
      "metadata": {
        "id": "y5JKzUUTGk1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Checking whether all parameters have updated or not**"
      ],
      "metadata": {
        "id": "HdqU6lCQuYf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_after=[]\n",
        "for  name,p in model.named_parameters():\n",
        "  params_after.append(p.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "DciFZ0pyud5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p1,p2 in zip(params_before, params_after):\n",
        "  print(np.sum(np.abs(p1-p2)))"
      ],
      "metadata": {
        "id": "0atso-cNusSU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}